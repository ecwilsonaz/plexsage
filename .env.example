# MediaSage Environment Variables
# Copy this file to .env and update with your actual values

# Plex Server Configuration
PLEX_URL=http://your-plex-server:32400
PLEX_TOKEN=your-plex-token

# LLM Provider (anthropic, openai, gemini, ollama, or custom)
# Defaults to gemini if not set. Can also be configured in UI.
#LLM_PROVIDER=gemini

# LLM Provider API Keys (set the one matching your provider)
#ANTHROPIC_API_KEY=sk-ant-your-key-here
#OPENAI_API_KEY=sk-your-key-here
#GEMINI_API_KEY=your-gemini-key-here

# Optional: Override default models (usually auto-detected from provider)
#LLM_MODEL_ANALYSIS=gemini-2.5-flash
#LLM_MODEL_GENERATION=gemini-2.5-flash

# =============================================================================
# Local LLM Settings (experimental)
# =============================================================================

# Ollama - runs models locally via Ollama
#LLM_PROVIDER=ollama
#OLLAMA_URL=http://localhost:11434
#OLLAMA_CONTEXT_WINDOW=32768
#LLM_MODEL_ANALYSIS=llama3:8b
#LLM_MODEL_GENERATION=llama3:8b

# Custom - any OpenAI-compatible API (OpenRouter, LM Studio, etc.)
#LLM_PROVIDER=custom
#CUSTOM_LLM_URL=https://openrouter.ai/api/v1
#CUSTOM_LLM_API_KEY=sk-or-your-key-here
#CUSTOM_CONTEXT_WINDOW=32768
#LLM_MODEL_ANALYSIS=meta-llama/llama-3-8b-instruct
#LLM_MODEL_GENERATION=meta-llama/llama-3-8b-instruct
